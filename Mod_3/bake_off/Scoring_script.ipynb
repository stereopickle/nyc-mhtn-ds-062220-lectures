{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = pd.read_csv('actuals.csv', names = ['answers'], header=0, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals.reset_index(drop=True, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7501, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answers    0.214371\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/swilson5/Documents/DSC/ds-062220/nyc-mhtn-ds-062220-lectures/Mod_3/bake_off/answers'\n",
    "extension = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['holdout_predictions_BZ.csv', 'submission-Albert_Um.csv', 'holdout_predictions_EMW.csv', 'final_pred_7501_AJC.csv', 'bakeoff_prediction_EB.csv', 'holdout_predictions_JS.csv', 'holdout_predictions_LC .csv', 'holdout_predictions_EA.csv', 'holdout_predictions_DS.csv', 'holdout_predictions_PT.csv', '_default_preds_JV.csv', 'holdout_prediction_YS.csv', 'holdout_predictions_KH.csv', 'default_preds_JB.csv', 'holdout_predictions_KO.csv', 'holdout_predictions_ML.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a list of all file names\n",
    "# starting with testlabels_ from the file\n",
    "\n",
    "os.chdir(path)\n",
    "files = glob.glob('*.{}'.format(extension))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary to store results\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BZ\n",
      "Um\n",
      "EMW\n",
      "AJC\n",
      "EB\n",
      "JS\n",
      "LC \n",
      "EA\n",
      "DS\n",
      "PT\n",
      "JV\n",
      "YS\n",
      "KH\n",
      "JB\n",
      "KO\n",
      "ML\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    name = file.split(\"_\")[-1].split(\".\")[0]\n",
    "    print(name)\n",
    "    guesses = pd.read_csv(file, header=None, index_col=0 )\n",
    "    # guesses.sort_index(inplace=True)\n",
    "\n",
    "    if guesses.shape[0] != 7501:\n",
    "        guesses = pd.read_csv(file, index_col=0 )\n",
    "        if guesses.shape[0] != 7501:\n",
    "            print(name, \"not the correct size\", guesses.shape[0]  )\n",
    "            continue\n",
    "    f1 = metrics.f1_score(actuals['answers'],guesses)\n",
    "    acc = metrics.accuracy_score(actuals['answers'],guesses)\n",
    "    results[name]= [acc, f1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now printing the results with in ascending order\n",
      "LC  achieved an F1 of 0.0 and a Accuracy of  0.7856285828556192\n",
      "\n",
      "YS achieved an F1 of 0.06189376443418013 and a Accuracy of  0.7292361018530863\n",
      "\n",
      "JV achieved an F1 of 0.23647518126045733 and a Accuracy of  0.6349820023996801\n",
      "\n",
      "KO achieved an F1 of 0.45999999999999996 and a Accuracy of  0.8056259165444607\n",
      "\n",
      "DS achieved an F1 of 0.46777697320782047 and a Accuracy of  0.8040261298493534\n",
      "\n",
      "AJC achieved an F1 of 0.5190763052208835 and a Accuracy of  0.7445673910145314\n",
      "\n",
      "KH achieved an F1 of 0.5243578387953941 and a Accuracy of  0.7852286361818425\n",
      "\n",
      "EMW achieved an F1 of 0.5250475586556754 and a Accuracy of  0.8002932942274363\n",
      "\n",
      "JS achieved an F1 of 0.5275344180225281 and a Accuracy of  0.798693507532329\n",
      "\n",
      "ML achieved an F1 of 0.5304543989687399 and a Accuracy of  0.8057592321023863\n",
      "\n",
      "PT achieved an F1 of 0.5318963006117099 and a Accuracy of  0.7857618984135448\n",
      "\n",
      "JB achieved an F1 of 0.5357350377687391 and a Accuracy of  0.7869617384348754\n",
      "\n",
      "EA achieved an F1 of 0.5402869757174393 and a Accuracy of  0.7778962804959338\n",
      "\n",
      "EB achieved an F1 of 0.5412226584408302 and a Accuracy of  0.7818957472337021\n",
      "\n",
      "UM achieved an F1 of 0.5466507177033493 and a Accuracy of  0.7978936141847753\n",
      "\n",
      "BZ achieved an F1 of 0.5502645502645502 and a Accuracy of  0.7960271963738168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Now printing the results with in ascending order')\n",
    "\n",
    "for k,v in sorted_results:\n",
    "#     print(v[1])\n",
    "    print('{} achieved an F1 of {} and a Accuracy of  {}\\n'.format(\n",
    "          k.upper(), v[1], v[0]))\n",
    "\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
